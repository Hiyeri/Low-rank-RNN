{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision making in low-rank recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1f735f8b490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#plt.style.use('dark_background')\n",
    "\n",
    "# For debugging we will use the below inside some functions.\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptual decision makingg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Create a function for generating the data.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining standard deviation and strength of stimulus\n",
    "std = 0.03\n",
    "stim_strength = std * np.hstack((-np.flip(2**np.arange(0,5)), 2**np.arange(0,5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check the dimensions needed for the target y.\n",
    "\n",
    "\n",
    "def generate_data(time_length, trials, stim_strength, std = 0.03):\n",
    "    \"\"\"\n",
    "    ksi is a normally distr noise with sigma 0.03.\n",
    "    u is an input\n",
    "    û is the stimulis strength\n",
    "    y is the target, i.e. the sign of û. \n",
    "    y's first dimension is time length and second is  trials. \n",
    "    \"\"\"\n",
    "    ksi = std * np.random.randn(time_length, trials)\n",
    "    \n",
    "  \n",
    "    û_value = np.random.choice(stim_strength, size=trials)\n",
    "    û = np.full_like(ksi, 0)\n",
    "    y = np.full_like(ksi, 1)\n",
    "    for i in range(trials):  # vectorize it??\n",
    "        û[5:46, i] = û_value[i]\n",
    "        y[:, i] = np.sign(û_value[i]) * y[:, i]\n",
    "    \n",
    "    return  torch.from_numpy(û + ksi).reshape([time_length, trials, 1, 1]), torch.from_numpy(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "\n",
    "T = 75\n",
    "trials = 8\n",
    "u, y = generate_data(T, trials, stim_strength)\n",
    "time = np.arange(0,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([75, 8, 1, 1]), torch.Size([75, 8]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "\n",
    "fig, axs = plt.subplots(1, trials, figsize=(15,2))\n",
    "\n",
    "fig.suptitle(\"Generate Data\")\n",
    "\n",
    "for i in range(trials):\n",
    "    axs[i].plot(time, u[:, i, 0, 0], label=\"stimulus\")\n",
    "    axs[i].plot(time, y[:, i], label=\"target\")\n",
    "    axs[i].set_title(f\"trial {i}\")\n",
    "    axs[i].set_ylim(-1.2, 1.2)\n",
    "axs[0].set_xlabel(\"time\")\n",
    "axs[0].set_ylabel(\"signal strength\")\n",
    "axs[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Implement the recurrent neural network in your favorite deep learning library.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J matrix has to have two trainable vectors m, and n as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vectorize input and targets and all into batch of time and trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: finish refactoring for batch dim, reduce the reshapings.\n",
    "\n",
    "def dynamics(x, u_of_t, tau, m,n,I):\n",
    "    J_of_phi_x = torch.div(torch.matmul(torch.matmul(m, n).float(), torch.tanh(x).float()), len(n))\n",
    "\n",
    "    return (-x + J_of_phi_x + u_of_t*I) / tau  # is broadcasting working for input and in weigths?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 124, 1]), torch.Size([2, 124, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dynamics.\n",
    "x = torch.randn([2,124,1])   # trials, size of the network, and 1 dimension\n",
    "I = torch.randn([124,1])   # size of the network and 1 dimension\n",
    "\n",
    "u, y = generate_data(74, 2, stim_strength) # time, trials, stimulis strength\n",
    "tau = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m = torch.randn(2, 124, 1)\n",
    "n = torch.randn(2, 1, 124)\n",
    "(u[50]*I).shape, dynamics(x, u[50], tau, m, n, I).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LR_RNN(nn.Module):\n",
    "    # Low-rank recurrent neural network without readout.\n",
    "    def __init__(self, N):\n",
    "        super().__init__()\n",
    "        # storign info\n",
    "        self.N = N\n",
    "        \n",
    "        # pattern from witch connectivity is made\n",
    "        tensor_m = torch.randn([N,1])\n",
    "        self.m = nn.Parameter(tensor_m)\n",
    "        \n",
    "        # pattern to which connectivity is made\n",
    "        tensor_n = torch.randn([1,N])\n",
    "        self.n = nn.Parameter(tensor_n)\n",
    "        \n",
    "        # input weights\n",
    "        self.I = torch.randn([N,1])\n",
    "        \n",
    "        # Output is defined separetly in different class below.\n",
    "\n",
    "          \n",
    "    def forward(self, x, u_of_t, tau, dt):\n",
    "        # It's an Euler method.\n",
    "        return x +  dt * dynamics(x, u_of_t, tau, self.m, self.n, self.I)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, trials, N):\n",
    "        super().__init__()\n",
    "        # storing info\n",
    "        self.N = N\n",
    "        \n",
    "        # the layer\n",
    "        self.lr_rnn = LR_RNN(N)\n",
    "        \n",
    "        # output layer\n",
    "        std_dev = 4\n",
    "        self.w = std_dev*torch.randn([1, N])\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, u_of_t, tau, dt):\n",
    "        \n",
    "        \"\"\"\n",
    "        Going forward with the low rank rnn and input.\n",
    "        Reading through electrode weights.\n",
    "        \"\"\"\n",
    "        x1 = self.lr_rnn(x, u_of_t, tau, dt)\n",
    "\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        \n",
    "        z = 1/self.N * torch.matmul(self.w.float(), torch.tanh(x1).float())\n",
    "        z.squeeze_()\n",
    "        return x1, z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([74, 2, 1, 1]), torch.Size([2, 512, 1]), torch.Size([2]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a_trials = 2\n",
    "a_model = Model(a_trials, 512)\n",
    "a_T = 74\n",
    "a_u, a_y = generate_data(a_T, a_trials, stim_strength)\n",
    "a_x = torch.zeros([a_trials,512,1])\n",
    "\n",
    "a_tau = 0.1\n",
    "a_dt = 0.02\n",
    "a_x, a_z = a_model(a_x, a_u[50], a_tau, a_dt)\n",
    "a_u.shape, a_x.shape, a_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check dimensions for multiplication self.w with tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "N = 124\n",
    "trials = 32    # Mini-batch size, minimum value is 2 (probably because of squeezing and broadcasting).\n",
    "model = Model(trials, N)\n",
    "x = torch.zeros([trials,N,1])\n",
    "\n",
    "tau = 0.1  # seconds\n",
    "dt = 0.02  # seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data.\n",
    "\n",
    "T = 75\n",
    "read_onset = 13  # how many last steps are read\n",
    "time = np.arange(0,T)\n",
    "u, y = generate_data(T, trials, stim_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 / 200 epoch mean error is  ------------   tensor(12.0158, grad_fn=<SumBackward0>)\n",
      "   1 / 200 epoch mean error is  ------------   tensor(12.0109, grad_fn=<SumBackward0>)\n",
      "   2 / 200 epoch mean error is  ------------   tensor(12.0075, grad_fn=<SumBackward0>)\n",
      "   3 / 200 epoch mean error is  ------------   tensor(12.0048, grad_fn=<SumBackward0>)\n",
      "   4 / 200 epoch mean error is  ------------   tensor(12.0027, grad_fn=<SumBackward0>)\n",
      "   5 / 200 epoch mean error is  ------------   tensor(12.0009, grad_fn=<SumBackward0>)\n",
      "   6 / 200 epoch mean error is  ------------   tensor(11.9994, grad_fn=<SumBackward0>)\n",
      "   7 / 200 epoch mean error is  ------------   tensor(11.9981, grad_fn=<SumBackward0>)\n",
      "   8 / 200 epoch mean error is  ------------   tensor(11.9969, grad_fn=<SumBackward0>)\n",
      "   9 / 200 epoch mean error is  ------------   tensor(11.9958, grad_fn=<SumBackward0>)\n",
      "   10 / 200 epoch mean error is  ------------   tensor(11.9947, grad_fn=<SumBackward0>)\n",
      "   11 / 200 epoch mean error is  ------------   tensor(11.9937, grad_fn=<SumBackward0>)\n",
      "   12 / 200 epoch mean error is  ------------   tensor(11.9928, grad_fn=<SumBackward0>)\n",
      "   13 / 200 epoch mean error is  ------------   tensor(11.9917, grad_fn=<SumBackward0>)\n",
      "   14 / 200 epoch mean error is  ------------   tensor(11.9907, grad_fn=<SumBackward0>)\n",
      "   15 / 200 epoch mean error is  ------------   tensor(11.9895, grad_fn=<SumBackward0>)\n",
      "   16 / 200 epoch mean error is  ------------   tensor(11.9882, grad_fn=<SumBackward0>)\n",
      "   17 / 200 epoch mean error is  ------------   tensor(11.9867, grad_fn=<SumBackward0>)\n",
      "   18 / 200 epoch mean error is  ------------   tensor(11.9850, grad_fn=<SumBackward0>)\n",
      "   19 / 200 epoch mean error is  ------------   tensor(11.9830, grad_fn=<SumBackward0>)\n",
      "   20 / 200 epoch mean error is  ------------   tensor(11.9806, grad_fn=<SumBackward0>)\n",
      "   21 / 200 epoch mean error is  ------------   tensor(11.9777, grad_fn=<SumBackward0>)\n",
      "   22 / 200 epoch mean error is  ------------   tensor(11.9739, grad_fn=<SumBackward0>)\n",
      "   23 / 200 epoch mean error is  ------------   tensor(11.9689, grad_fn=<SumBackward0>)\n",
      "   24 / 200 epoch mean error is  ------------   tensor(11.9617, grad_fn=<SumBackward0>)\n",
      "   25 / 200 epoch mean error is  ------------   tensor(11.9502, grad_fn=<SumBackward0>)\n",
      "   26 / 200 epoch mean error is  ------------   tensor(11.9275, grad_fn=<SumBackward0>)\n",
      "   27 / 200 epoch mean error is  ------------   tensor(11.8607, grad_fn=<SumBackward0>)\n",
      "   28 / 200 epoch mean error is  ------------   tensor(11.5232, grad_fn=<SumBackward0>)\n",
      "   29 / 200 epoch mean error is  ------------   tensor(10.3179, grad_fn=<SumBackward0>)\n",
      "   30 / 200 epoch mean error is  ------------   tensor(8.5788, grad_fn=<SumBackward0>)\n",
      "   31 / 200 epoch mean error is  ------------   tensor(7.4919, grad_fn=<SumBackward0>)\n",
      "   32 / 200 epoch mean error is  ------------   tensor(6.9782, grad_fn=<SumBackward0>)\n",
      "   33 / 200 epoch mean error is  ------------   tensor(8.3298, grad_fn=<SumBackward0>)\n",
      "   34 / 200 epoch mean error is  ------------   tensor(8.6308, grad_fn=<SumBackward0>)\n",
      "   35 / 200 epoch mean error is  ------------   tensor(10.9179, grad_fn=<SumBackward0>)\n",
      "   36 / 200 epoch mean error is  ------------   tensor(12.2899, grad_fn=<SumBackward0>)\n",
      "   37 / 200 epoch mean error is  ------------   tensor(13.1064, grad_fn=<SumBackward0>)\n",
      "   38 / 200 epoch mean error is  ------------   tensor(13.2336, grad_fn=<SumBackward0>)\n",
      "   39 / 200 epoch mean error is  ------------   tensor(13.3216, grad_fn=<SumBackward0>)\n",
      "   40 / 200 epoch mean error is  ------------   tensor(14.1032, grad_fn=<SumBackward0>)\n",
      "   41 / 200 epoch mean error is  ------------   tensor(14.1167, grad_fn=<SumBackward0>)\n",
      "   42 / 200 epoch mean error is  ------------   tensor(14.0912, grad_fn=<SumBackward0>)\n",
      "   43 / 200 epoch mean error is  ------------   tensor(14.0339, grad_fn=<SumBackward0>)\n",
      "   44 / 200 epoch mean error is  ------------   tensor(13.9522, grad_fn=<SumBackward0>)\n",
      "   45 / 200 epoch mean error is  ------------   tensor(13.8529, grad_fn=<SumBackward0>)\n",
      "   46 / 200 epoch mean error is  ------------   tensor(13.7422, grad_fn=<SumBackward0>)\n",
      "   47 / 200 epoch mean error is  ------------   tensor(13.6253, grad_fn=<SumBackward0>)\n",
      "   48 / 200 epoch mean error is  ------------   tensor(13.5063, grad_fn=<SumBackward0>)\n",
      "   49 / 200 epoch mean error is  ------------   tensor(13.3885, grad_fn=<SumBackward0>)\n",
      "   50 / 200 epoch mean error is  ------------   tensor(13.2742, grad_fn=<SumBackward0>)\n",
      "   51 / 200 epoch mean error is  ------------   tensor(13.1650, grad_fn=<SumBackward0>)\n",
      "   52 / 200 epoch mean error is  ------------   tensor(13.0618, grad_fn=<SumBackward0>)\n",
      "   53 / 200 epoch mean error is  ------------   tensor(12.9653, grad_fn=<SumBackward0>)\n",
      "   54 / 200 epoch mean error is  ------------   tensor(12.3627, grad_fn=<SumBackward0>)\n",
      "   55 / 200 epoch mean error is  ------------   tensor(12.2999, grad_fn=<SumBackward0>)\n",
      "   56 / 200 epoch mean error is  ------------   tensor(12.2438, grad_fn=<SumBackward0>)\n",
      "   57 / 200 epoch mean error is  ------------   tensor(12.1938, grad_fn=<SumBackward0>)\n",
      "   58 / 200 epoch mean error is  ------------   tensor(12.1493, grad_fn=<SumBackward0>)\n",
      "   59 / 200 epoch mean error is  ------------   tensor(12.1097, grad_fn=<SumBackward0>)\n",
      "   60 / 200 epoch mean error is  ------------   tensor(12.0744, grad_fn=<SumBackward0>)\n",
      "   61 / 200 epoch mean error is  ------------   tensor(12.0431, grad_fn=<SumBackward0>)\n",
      "   62 / 200 epoch mean error is  ------------   tensor(12.0153, grad_fn=<SumBackward0>)\n",
      "   63 / 200 epoch mean error is  ------------   tensor(11.9906, grad_fn=<SumBackward0>)\n",
      "   64 / 200 epoch mean error is  ------------   tensor(11.6033, grad_fn=<SumBackward0>)\n",
      "   65 / 200 epoch mean error is  ------------   tensor(10.8869, grad_fn=<SumBackward0>)\n",
      "   66 / 200 epoch mean error is  ------------   tensor(10.5523, grad_fn=<SumBackward0>)\n",
      "   67 / 200 epoch mean error is  ------------   tensor(10.5692, grad_fn=<SumBackward0>)\n",
      "   68 / 200 epoch mean error is  ------------   tensor(10.5831, grad_fn=<SumBackward0>)\n",
      "   69 / 200 epoch mean error is  ------------   tensor(10.5942, grad_fn=<SumBackward0>)\n",
      "   70 / 200 epoch mean error is  ------------   tensor(10.6025, grad_fn=<SumBackward0>)\n",
      "   71 / 200 epoch mean error is  ------------   tensor(10.6083, grad_fn=<SumBackward0>)\n",
      "   72 / 200 epoch mean error is  ------------   tensor(10.6118, grad_fn=<SumBackward0>)\n",
      "   73 / 200 epoch mean error is  ------------   tensor(10.6130, grad_fn=<SumBackward0>)\n",
      "   74 / 200 epoch mean error is  ------------   tensor(10.6123, grad_fn=<SumBackward0>)\n",
      "   75 / 200 epoch mean error is  ------------   tensor(10.6098, grad_fn=<SumBackward0>)\n",
      "   76 / 200 epoch mean error is  ------------   tensor(10.6057, grad_fn=<SumBackward0>)\n",
      "   77 / 200 epoch mean error is  ------------   tensor(10.6002, grad_fn=<SumBackward0>)\n",
      "   78 / 200 epoch mean error is  ------------   tensor(10.5935, grad_fn=<SumBackward0>)\n",
      "   79 / 200 epoch mean error is  ------------   tensor(10.5856, grad_fn=<SumBackward0>)\n",
      "   80 / 200 epoch mean error is  ------------   tensor(10.5769, grad_fn=<SumBackward0>)\n",
      "   81 / 200 epoch mean error is  ------------   tensor(10.5674, grad_fn=<SumBackward0>)\n",
      "   82 / 200 epoch mean error is  ------------   tensor(10.5573, grad_fn=<SumBackward0>)\n",
      "   83 / 200 epoch mean error is  ------------   tensor(10.5467, grad_fn=<SumBackward0>)\n",
      "   84 / 200 epoch mean error is  ------------   tensor(10.5357, grad_fn=<SumBackward0>)\n",
      "   85 / 200 epoch mean error is  ------------   tensor(10.8826, grad_fn=<SumBackward0>)\n",
      "   86 / 200 epoch mean error is  ------------   tensor(11.6020, grad_fn=<SumBackward0>)\n",
      "   87 / 200 epoch mean error is  ------------   tensor(11.9742, grad_fn=<SumBackward0>)\n",
      "   88 / 200 epoch mean error is  ------------   tensor(11.9805, grad_fn=<SumBackward0>)\n",
      "   89 / 200 epoch mean error is  ------------   tensor(11.9851, grad_fn=<SumBackward0>)\n",
      "   90 / 200 epoch mean error is  ------------   tensor(11.9880, grad_fn=<SumBackward0>)\n",
      "   91 / 200 epoch mean error is  ------------   tensor(11.9892, grad_fn=<SumBackward0>)\n",
      "   92 / 200 epoch mean error is  ------------   tensor(11.9890, grad_fn=<SumBackward0>)\n",
      "   93 / 200 epoch mean error is  ------------   tensor(11.9875, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   94 / 200 epoch mean error is  ------------   tensor(11.9847, grad_fn=<SumBackward0>)\n",
      "   95 / 200 epoch mean error is  ------------   tensor(11.9810, grad_fn=<SumBackward0>)\n",
      "   96 / 200 epoch mean error is  ------------   tensor(11.9763, grad_fn=<SumBackward0>)\n",
      "   97 / 200 epoch mean error is  ------------   tensor(11.2383, grad_fn=<SumBackward0>)\n",
      "   98 / 200 epoch mean error is  ------------   tensor(11.2385, grad_fn=<SumBackward0>)\n",
      "   99 / 200 epoch mean error is  ------------   tensor(10.8792, grad_fn=<SumBackward0>)\n",
      "   100 / 200 epoch mean error is  ------------   tensor(10.5216, grad_fn=<SumBackward0>)\n",
      "   101 / 200 epoch mean error is  ------------   tensor(10.5232, grad_fn=<SumBackward0>)\n",
      "   102 / 200 epoch mean error is  ------------   tensor(10.5231, grad_fn=<SumBackward0>)\n",
      "   103 / 200 epoch mean error is  ------------   tensor(10.5213, grad_fn=<SumBackward0>)\n",
      "   104 / 200 epoch mean error is  ------------   tensor(10.5182, grad_fn=<SumBackward0>)\n",
      "   105 / 200 epoch mean error is  ------------   tensor(10.8768, grad_fn=<SumBackward0>)\n",
      "   106 / 200 epoch mean error is  ------------   tensor(10.8743, grad_fn=<SumBackward0>)\n",
      "   107 / 200 epoch mean error is  ------------   tensor(11.2380, grad_fn=<SumBackward0>)\n",
      "   108 / 200 epoch mean error is  ------------   tensor(11.2379, grad_fn=<SumBackward0>)\n",
      "   109 / 200 epoch mean error is  ------------   tensor(11.2378, grad_fn=<SumBackward0>)\n",
      "   110 / 200 epoch mean error is  ------------   tensor(11.9866, grad_fn=<SumBackward0>)\n",
      "   111 / 200 epoch mean error is  ------------   tensor(11.9885, grad_fn=<SumBackward0>)\n",
      "   112 / 200 epoch mean error is  ------------   tensor(11.9887, grad_fn=<SumBackward0>)\n",
      "   113 / 200 epoch mean error is  ------------   tensor(11.9874, grad_fn=<SumBackward0>)\n",
      "   114 / 200 epoch mean error is  ------------   tensor(11.2377, grad_fn=<SumBackward0>)\n",
      "   115 / 200 epoch mean error is  ------------   tensor(11.2377, grad_fn=<SumBackward0>)\n",
      "   116 / 200 epoch mean error is  ------------   tensor(10.8686, grad_fn=<SumBackward0>)\n",
      "   117 / 200 epoch mean error is  ------------   tensor(10.8692, grad_fn=<SumBackward0>)\n",
      "   118 / 200 epoch mean error is  ------------   tensor(10.8693, grad_fn=<SumBackward0>)\n",
      "   119 / 200 epoch mean error is  ------------   tensor(10.8690, grad_fn=<SumBackward0>)\n",
      "   120 / 200 epoch mean error is  ------------   tensor(10.8684, grad_fn=<SumBackward0>)\n",
      "   121 / 200 epoch mean error is  ------------   tensor(10.8674, grad_fn=<SumBackward0>)\n",
      "   122 / 200 epoch mean error is  ------------   tensor(10.8661, grad_fn=<SumBackward0>)\n",
      "   123 / 200 epoch mean error is  ------------   tensor(10.8646, grad_fn=<SumBackward0>)\n",
      "   124 / 200 epoch mean error is  ------------   tensor(11.2377, grad_fn=<SumBackward0>)\n",
      "   125 / 200 epoch mean error is  ------------   tensor(11.2377, grad_fn=<SumBackward0>)\n",
      "   126 / 200 epoch mean error is  ------------   tensor(11.2378, grad_fn=<SumBackward0>)\n",
      "   127 / 200 epoch mean error is  ------------   tensor(11.6192, grad_fn=<SumBackward0>)\n",
      "   128 / 200 epoch mean error is  ------------   tensor(11.6200, grad_fn=<SumBackward0>)\n",
      "   129 / 200 epoch mean error is  ------------   tensor(11.6202, grad_fn=<SumBackward0>)\n",
      "   130 / 200 epoch mean error is  ------------   tensor(11.2378, grad_fn=<SumBackward0>)\n",
      "   131 / 200 epoch mean error is  ------------   tensor(11.2378, grad_fn=<SumBackward0>)\n",
      "   132 / 200 epoch mean error is  ------------   tensor(10.8586, grad_fn=<SumBackward0>)\n",
      "   133 / 200 epoch mean error is  ------------   tensor(10.8585, grad_fn=<SumBackward0>)\n",
      "   134 / 200 epoch mean error is  ------------   tensor(10.8580, grad_fn=<SumBackward0>)\n",
      "   135 / 200 epoch mean error is  ------------   tensor(10.8573, grad_fn=<SumBackward0>)\n",
      "   136 / 200 epoch mean error is  ------------   tensor(10.8563, grad_fn=<SumBackward0>)\n",
      "   137 / 200 epoch mean error is  ------------   tensor(11.2381, grad_fn=<SumBackward0>)\n",
      "   138 / 200 epoch mean error is  ------------   tensor(11.6249, grad_fn=<SumBackward0>)\n",
      "   139 / 200 epoch mean error is  ------------   tensor(11.6255, grad_fn=<SumBackward0>)\n",
      "   140 / 200 epoch mean error is  ------------   tensor(11.6256, grad_fn=<SumBackward0>)\n",
      "   141 / 200 epoch mean error is  ------------   tensor(10.8537, grad_fn=<SumBackward0>)\n",
      "   142 / 200 epoch mean error is  ------------   tensor(10.8537, grad_fn=<SumBackward0>)\n",
      "   143 / 200 epoch mean error is  ------------   tensor(10.8534, grad_fn=<SumBackward0>)\n",
      "   144 / 200 epoch mean error is  ------------   tensor(10.8528, grad_fn=<SumBackward0>)\n",
      "   145 / 200 epoch mean error is  ------------   tensor(10.8519, grad_fn=<SumBackward0>)\n",
      "   146 / 200 epoch mean error is  ------------   tensor(10.8509, grad_fn=<SumBackward0>)\n",
      "   147 / 200 epoch mean error is  ------------   tensor(11.6305, grad_fn=<SumBackward0>)\n",
      "   148 / 200 epoch mean error is  ------------   tensor(11.6315, grad_fn=<SumBackward0>)\n",
      "   149 / 200 epoch mean error is  ------------   tensor(11.2415, grad_fn=<SumBackward0>)\n",
      "   150 / 200 epoch mean error is  ------------   tensor(11.2415, grad_fn=<SumBackward0>)\n",
      "   151 / 200 epoch mean error is  ------------   tensor(10.8486, grad_fn=<SumBackward0>)\n",
      "   152 / 200 epoch mean error is  ------------   tensor(10.8483, grad_fn=<SumBackward0>)\n",
      "   153 / 200 epoch mean error is  ------------   tensor(10.8478, grad_fn=<SumBackward0>)\n",
      "   154 / 200 epoch mean error is  ------------   tensor(11.2419, grad_fn=<SumBackward0>)\n",
      "   155 / 200 epoch mean error is  ------------   tensor(11.2421, grad_fn=<SumBackward0>)\n",
      "   156 / 200 epoch mean error is  ------------   tensor(11.2422, grad_fn=<SumBackward0>)\n",
      "   157 / 200 epoch mean error is  ------------   tensor(11.2423, grad_fn=<SumBackward0>)\n",
      "   158 / 200 epoch mean error is  ------------   tensor(11.2423, grad_fn=<SumBackward0>)\n",
      "   159 / 200 epoch mean error is  ------------   tensor(10.8452, grad_fn=<SumBackward0>)\n",
      "   160 / 200 epoch mean error is  ------------   tensor(10.8449, grad_fn=<SumBackward0>)\n",
      "   161 / 200 epoch mean error is  ------------   tensor(11.2426, grad_fn=<SumBackward0>)\n",
      "   162 / 200 epoch mean error is  ------------   tensor(11.2428, grad_fn=<SumBackward0>)\n",
      "   163 / 200 epoch mean error is  ------------   tensor(10.8435, grad_fn=<SumBackward0>)\n",
      "   164 / 200 epoch mean error is  ------------   tensor(11.2431, grad_fn=<SumBackward0>)\n",
      "   165 / 200 epoch mean error is  ------------   tensor(11.2432, grad_fn=<SumBackward0>)\n",
      "   166 / 200 epoch mean error is  ------------   tensor(10.8424, grad_fn=<SumBackward0>)\n",
      "   167 / 200 epoch mean error is  ------------   tensor(10.8420, grad_fn=<SumBackward0>)\n",
      "   168 / 200 epoch mean error is  ------------   tensor(11.2437, grad_fn=<SumBackward0>)\n",
      "   169 / 200 epoch mean error is  ------------   tensor(11.2439, grad_fn=<SumBackward0>)\n",
      "   170 / 200 epoch mean error is  ------------   tensor(11.2440, grad_fn=<SumBackward0>)\n",
      "   171 / 200 epoch mean error is  ------------   tensor(10.4376, grad_fn=<SumBackward0>)\n",
      "   172 / 200 epoch mean error is  ------------   tensor(11.2444, grad_fn=<SumBackward0>)\n",
      "   173 / 200 epoch mean error is  ------------   tensor(11.2446, grad_fn=<SumBackward0>)\n",
      "   174 / 200 epoch mean error is  ------------   tensor(10.8397, grad_fn=<SumBackward0>)\n",
      "   175 / 200 epoch mean error is  ------------   tensor(11.2451, grad_fn=<SumBackward0>)\n",
      "   176 / 200 epoch mean error is  ------------   tensor(10.8388, grad_fn=<SumBackward0>)\n",
      "   177 / 200 epoch mean error is  ------------   tensor(11.2455, grad_fn=<SumBackward0>)\n",
      "   178 / 200 epoch mean error is  ------------   tensor(10.8379, grad_fn=<SumBackward0>)\n",
      "   179 / 200 epoch mean error is  ------------   tensor(11.2460, grad_fn=<SumBackward0>)\n",
      "   180 / 200 epoch mean error is  ------------   tensor(10.8370, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-6180bf9af6db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;31m# Computation and storage of the results.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mz_squeezed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-923cbb04cfd5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, u_of_t, tau, dt)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mReading\u001b[0m \u001b[0mthrough\u001b[0m \u001b[0melectrode\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \"\"\"\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_of_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-32380c45c340>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, u_of_t, tau, dt)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_of_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# It's an Euler method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_of_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-eed4a4aa7cfe>\u001b[0m in \u001b[0;36mdynamics\u001b[1;34m(x, u_of_t, tau, m, n, I)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_of_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mJ_of_phi_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mJ_of_phi_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mu_of_t\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtau\u001b[0m  \u001b[1;31m# is broadcasting working for input and in weigths?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mformat_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 filename, lineno, name, lookup_line=False, locals=f_locals))\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;31m# If immediate lookup was desired, trigger lookups now.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\compilerop.py\u001b[0m in \u001b[0;36mcheck_linecache_ipython\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \"\"\"\n\u001b[0;32m    156\u001b[0m     \u001b[1;31m# First call the original checkcache as intended\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkcache_ori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[1;31m# Then, update back the cache with our data, so that tracebacks related\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# to our compiled codes can be produced.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\linecache.py\u001b[0m in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mcontinue\u001b[0m   \u001b[1;31m# no-op for files loaded via a __loader__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training:\n",
    "\n",
    "From the readout onset the network is unrolled \n",
    "\n",
    "and the backpropagation goes back in time until the beginning of the readout.\n",
    "\n",
    "Backprop is called after computing the error on the whole batch.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005)\n",
    "loss_record = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "        target = torch.zeros([read_onset, trials])\n",
    "        x = [None]*(read_onset+1)\n",
    "        x[0] = torch.zeros([trials, model.N, 1])\n",
    "        losses = torch.zeros(read_onset)\n",
    "\n",
    "        for t in range(T-read_onset):\n",
    "\n",
    "            x[0] = model.lr_rnn.forward(x[0], u[t], tau, dt)\n",
    "            \n",
    "\n",
    "        x[0].detach_()\n",
    "        \n",
    "        \n",
    "        \n",
    "        for k in range(read_onset-1):\n",
    "\n",
    "            # Initializations.\n",
    "            t = T - read_onset + k        \n",
    "            \n",
    "            \n",
    "            # Computation and storage of the results.                \n",
    "            x[k+1], z = model.forward(x[k], u[t], tau, dt)\n",
    "            z_squeezed = z.squeeze()\n",
    "\n",
    "            \n",
    "            # use the error or mse.\n",
    "            losses[k+1] = mse_loss(z_squeezed, y[t+1, :].float())\n",
    "            \n",
    "            # TODO: sum and store loss through time\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        optimizer.zero_grad()  # Reset the gradient values.\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    " \n",
    "        loss = torch.sum(losses)\n",
    "        losses[-1].backward()  # Compute the gradients.\n",
    "\n",
    "        optimizer.step()  # Parameters update.\n",
    "            \n",
    "        \n",
    "        loss_record.append(loss.detach())    \n",
    "        #if epoch%10 == 0:\n",
    "        \n",
    "        print(\"  \", epoch,\"/\",epochs, \"epoch mean error is  ------------  \", loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss, loss_sum\n",
    "np.sum(loss_record[-16:-1])/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why $x$ should be set to zero after each trial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground sketch.\n",
    "\n",
    "abatch = 11\n",
    "\n",
    "am = torch.randn([N,1])\n",
    "an = torch.randn([1,N])\n",
    "aT = 77\n",
    "#torch.matmul(torch.matmul(am,an), torch.tanh(ax)).shape, \n",
    "\n",
    "ax = torch.randn([abatch, N, 1])\n",
    "au = torch.randn([aT, abatch, 1, 1])\n",
    "\n",
    "aw = torch.randn([1, N])\n",
    "aI = torch.randn([N,1])\n",
    "\n",
    "au, ay = generate_data(abatch, aT, stim_strength)\n",
    "\n",
    "(ax+au[61]*aI).shape\n",
    "\n",
    "z = 1/N * torch.matmul(aw, torch.tanh(ax))\n",
    "z.squeeze_().shape, ay[:,72].shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
